{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaZAOVY6Iu3p"
   },
   "source": [
    "**Name:** Bala Guga Gopal S\n",
    "\n",
    "**Script Name:** Familiarization with Keras\n",
    "\n",
    "**Script Description:** Familiarization of keras using python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIE_pZQpvggw"
   },
   "source": [
    "**Script is divided into **\n",
    "\n",
    "* Introduction\n",
    "* Installation\n",
    "* Backend Configuration\n",
    "* Overview of Deep learning\n",
    "* Deep learnings\n",
    "* Modules\n",
    "* Customized Layer\n",
    "* Models\n",
    "* Model Compilation\n",
    "\n",
    "source - https://www.tutorialspoint.com/keras/index.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP-uLrvAwahL"
   },
   "source": [
    "Prerequisites\n",
    "\n",
    "Before proceeding with the various types ofs concepts given in this tutorial, we assume that the readers have basic understanding of deep learning framework. In addition to this, it will be very helpful, if the readers have a sound knowledge of Python and Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzesqO4TwXid"
   },
   "source": [
    "Introduction\n",
    "\n",
    "Keras is an open source deep learning framework for python. It has been developed by an artificial intelligence researcher at Google named Francois Chollet. Leading organizations like Google, Square, Netflix, Huawei and Uber are currently using Keras. This tutorial walks through the installation of Keras, basics of deep learning, Keras models, Keras layers, Keras modules and finally conclude with some real-time applications.\n",
    "\n",
    "Keras leverages various optimization techniques to make high level neural network API easier and more performant. It supports the following features −\n",
    "\n",
    "    Consistent, simple and extensible API.\n",
    "    Minimal structure - easy to achieve the result without any frills.\n",
    "    It supports multiple platforms and backends.\n",
    "    It is user friendly framework which runs on both CPU and GPU.\n",
    "    Highly scalability of computation.\n",
    "\n",
    "Keras is highly powerful and dynamic framework and comes up with the following advantages −\n",
    "\n",
    "    Larger community support.\n",
    "    Easy to test.\n",
    "    Keras neural networks are written in Python which makes things simpler.\n",
    "    Keras supports both convolution and recurrent networks.\n",
    "    Deep learning models are discrete components, so that, you can combine into many ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgntlg8TwhAb"
   },
   "source": [
    "# Installation\n",
    "\n",
    "Keras depends on the following python libraries.\n",
    "\n",
    "    Numpy\n",
    "    Pandas\n",
    "    Scikit-learn\n",
    "    Matplotlib\n",
    "    Scipy\n",
    "    Seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17836,
     "status": "ok",
     "timestamp": 1650203435462,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "dyGcNH3oyBox",
    "outputId": "9759a698-fb05-4ea3-95b3-bd49384ebc09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scipy\n",
    "!pip install -U scikit-learn\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3063,
     "status": "ok",
     "timestamp": 1650203467090,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "METZ2EO9x_33",
    "outputId": "486048bb-423a-414c-e0b8-191ae20c0227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPS4KSMnzUhR"
   },
   "source": [
    "TensorFlow and Theano is used as Keras backend implementations.\n",
    "\n",
    "**TensorFlow** is an open source machine learning library used for numerical computational tasks developed by Google. Keras is a high level API built on top of TensorFlow or Theano. \n",
    "\n",
    "**Theano** is an open source deep learning library that allows you to evaluate multi-dimensional arrays effectively. \n",
    "\n",
    "By default, keras uses TensorFlow backend. If you want to change backend configuration from TensorFlow to Theano, just change the backend = theano in keras.json file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f_LHJNI0wKD"
   },
   "source": [
    "# Keras models, Keras layers and Keras modules.\n",
    "\n",
    "Architecture of Keras. Keras API can be divided into three main categories −\n",
    "\n",
    "    Model\n",
    "    Layer\n",
    "    Core Modules\n",
    "\n",
    "## Model\n",
    "\n",
    "Keras Models are of two types as mentioned below −\n",
    "\n",
    "**Sequential Model** − Sequential model is basically a linear composition of Keras Layers. Sequential model is easy, minimal as well as has the ability to represent nearly all available neural networks.\n",
    "\n",
    "A simple sequential model is as follows − "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2290,
     "status": "ok",
     "timestamp": 1650204092959,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "OLalyI0T0x6v"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "\n",
    "model = Sequential()  \n",
    "model.add(Dense(512, activation = 'relu', input_shape = (784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFtjIHRx1Bg7"
   },
   "source": [
    "Where,\n",
    "\n",
    "    Line 1 imports Sequential model from Keras models\n",
    "    Line 2 imports Dense layer and Activation module\n",
    "    Line 4 create a new sequential model using Sequential API\n",
    "    Line 5 adds a dense layer (Dense API) with relu activation (using Activation module) function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb2ZUk1s_9oM"
   },
   "source": [
    "The core idea of Sequential API is simply arranging the Keras layers in a sequential order and so, it is called Sequential API. Most of the ANN also has layers in sequential order and the data flows from one layer to another layer in the given order until the data finally reaches the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1574,
     "status": "ok",
     "timestamp": 1650206973768,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "k-OLHzzd_-aQ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1650207013482,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "tobrhm7c_9L8"
   },
   "outputs": [],
   "source": [
    "# Add layers\n",
    "from keras.models import Sequential \n",
    "\n",
    "model = Sequential() \n",
    "input_layer = Dense(32, input_shape=(8,)) \n",
    "model.add(input_layer) \n",
    "hidden_layer = Dense(64, activation='relu'); model.add(hidden_layer) \n",
    "output_layer = Dense(8) \n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipgXU3RMAQHr"
   },
   "source": [
    "Access the model\n",
    "\n",
    "Keras provides few methods to get the model information like layers, input data and output data. They are as follows −\n",
    "\n",
    "    model.layers − Returns all the layers of the model as list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1650207101590,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "6l7cKskcAR3t",
    "outputId": "08c9c4b4-9bdd-418f-84a5-a58a2a7980ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'dense_11')>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = model.layers\n",
    "layers\n",
    "inputs = model.inputs \n",
    "inputs \n",
    "outputs = model.outputs \n",
    "outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnaV7LEq1p2K"
   },
   "source": [
    "## Layer\n",
    "\n",
    "Each Keras layer in the Keras model represent the corresponding layer (input layer, hidden layer and output layer) in the actual proposed neural network model. Keras provides a lot of pre-build layers so that any complex neural network can be easily created. Some of the important Keras layers are specified below,\n",
    "\n",
    "    Core Layers\n",
    "    Convolution Layers\n",
    "    Pooling Layers\n",
    "    Recurrent Layers\n",
    "\n",
    "A simple python code to represent a neural network model using sequential model is as follows −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650204388791,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "1YkwciSG1xxo"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Dropout \n",
    "\n",
    "model = Sequential() \n",
    "model.add(Dense(512, activation = 'relu', input_shape = (784,))) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(512, activation = 'relu')) \n",
    "model.add(Dropout(0.2)) \n",
    "#model.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4IcvjZ395fs"
   },
   "source": [
    "Where,\n",
    "\n",
    "    Line 1 imports Sequential model from Keras models\n",
    "    Line 2 imports Dense layer and Activation module\n",
    "    Line 4 create a new sequential model using Sequential API\n",
    "    Line 5 adds a dense layer (Dense API) with relu activation (using Activation module) function.\n",
    "    Line 6 adds a dropout layer (Dropout API) to handle over-fitting.\n",
    "    Line 7 adds another dense layer (Dense API) with relu activation (using Activation module) function.\n",
    "    Line 8 adds another dropout layer (Dropout API) to handle over-fitting.\n",
    "    Line 9 adds final dense layer (Dense API) with softmax activation (using Activation module) function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyxXbPb49_Ja"
   },
   "source": [
    "A simple Keras layer using Sequential model API to get the idea of how Keras model and layer works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1650206358831,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "or0EFYfW9lG1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense \n",
    "from keras import initializers \n",
    "from keras import regularizers \n",
    "from keras import constraints \n",
    "\n",
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(32, input_shape=(16,), kernel_initializer = 'he_uniform', \n",
    "   kernel_regularizer = None, kernel_constraint = 'MaxNorm', activation = 'relu')) \n",
    "model.add(Dense(16, activation = 'relu')) \n",
    "model.add(Dense(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHjlkgf69kra"
   },
   "source": [
    "where,\n",
    "\n",
    "    Line 1-5 imports the necessary modules.\n",
    "    Line 7 creates a new model using Sequential API.\n",
    "    Line 9 creates a new Dense layer and add it into the model. Dense is an entry level layer provided by Keras, which accepts the number of neurons or units (32) as its required parameter. If the layer is first layer, then we need to provide Input Shape, (16,) as well. Otherwise, the output of the previous layer will be used as input of the next layer. All other parameters are optional.\n",
    "        First parameter represents the number of units (neurons).\n",
    "        input_shape represent the shape of input data.\n",
    "        kernel_initializer represent initializer to be used. he_uniform function is set as value.\n",
    "        kernel_regularizer represent regularizer to be used. None is set as value.\n",
    "        kernel_constraint represent constraint to be used. MaxNorm function is set as value.activation represent activation to be used. relu function is set as value.\n",
    "\n",
    "    Line 10 creates second Dense layer with 16 units and set relu as the activation function.\n",
    "    Line 11 creates final Dense layer with 8 units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9zmA2iD2Qku"
   },
   "source": [
    "## Core Modules\n",
    "\n",
    "Keras also provides a lot of built-in neural network related functions to properly create the Keras model and Keras layers. Some of the function are as follows −\n",
    "\n",
    "    **Activations module** − Activation function is an important concept in ANN and activation modules provides many activation function like softmax, relu, etc.,\n",
    "    **Loss module** − Loss module provides loss functions like mean_squared_error, mean_absolute_error, poisson, etc.,\n",
    "    **Optimizer module** − Optimizer module provides optimizer function like adam, sgd, etc.,\n",
    "    **Regularizers** − Regularizer module provides functions like L1 regularizer, L2 regularizer, etc.,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tPX6X5g-t5J"
   },
   "source": [
    "## CUSTOMIZED layer\n",
    "\n",
    "Keras allows to create our own customized layer. Once a new layer is created, it can be used in any model without any restriction. \n",
    "\n",
    "Keras provides a base layer class, Layer which can sub-classed to create our own customized layer. Let us create a simple layer which will find weight based on normal distribution and then do the basic computation of finding the summation of the product of input and its weight during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1650206703789,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "Drb_JnEv-7Sr"
   },
   "outputs": [],
   "source": [
    "# Import lib\n",
    "from keras import backend as K \n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1650206826831,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "LxiscE2o_Inu"
   },
   "outputs": [],
   "source": [
    "# Class for custom layer\n",
    "\n",
    "class MyCustomLayer(Layer): \n",
    "   def __init__(self, output_dim, **kwargs): \n",
    "      self.output_dim = output_dim \n",
    "      super(MyCustomLayer, self).__init__(**kwargs) \n",
    "   def build(self, input_shape): \n",
    "     self.kernel = self.add_weight(name = 'kernel', \n",
    "      shape = (input_shape[1], self.output_dim), \n",
    "      initializer = 'normal', trainable = True) \n",
    "     super(MyCustomLayer, self).build(input_shape) \n",
    "     #Be sure to call this at the end \n",
    "   def call(self, input_data): return K.dot(input_data, self.kernel) \n",
    "   def compute_output_shape(self, input_shape): return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1650206861907,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "deRnwlIs_ig6",
    "outputId": "aa19302b-5197-4b4b-d84b-1c0fce0912b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_custom_layer (MyCustomLa  (None, 32)               512       \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 776\n",
      "Trainable params: 776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Using our customized layer\n",
    "\n",
    "# Let us create a simple model using our customized layer as specified below −\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "\n",
    "model = Sequential() \n",
    "model.add(MyCustomLayer(32, input_shape = (16,))) \n",
    "model.add(Dense(8, activation = 'softmax')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au3uuH_9Autf"
   },
   "source": [
    "# Model Compilation\n",
    "\n",
    "## Loss\n",
    "\n",
    "Loss function is used to find error or deviation in the learning process. Keras requires loss function during model compilation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1650207442032,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "1Dz1rjUjAuNp"
   },
   "outputs": [],
   "source": [
    "# For Loss (Loss function is used to find error or deviation in the learning process. Keras requires loss function during model compilation process)\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJnBT-bIBTNW"
   },
   "source": [
    "## Optimizer\n",
    "\n",
    "In machine learning, Optimization is an important process which optimize the input weights by comparing the prediction and the loss function. Keras provides quite a few optimizer as a module, optimizers and they are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMUBSXtmBS33"
   },
   "outputs": [],
   "source": [
    "# SGD − Stochastic gradient descent optimizer.\n",
    "from keras import optimizers\n",
    "keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.0, nesterov = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSC1DXLjChDQ"
   },
   "outputs": [],
   "source": [
    "# RMSprop − RMSProp optimizer.\n",
    "keras.optimizers.RMSprop(learning_rate = 0.001, rho = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zx7rOck0CsvZ"
   },
   "outputs": [],
   "source": [
    "#Adagrad − Adagrad optimizer.\n",
    "keras.optimizers.Adagrad(learning_rate = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wsvp40GvCxCD"
   },
   "outputs": [],
   "source": [
    "#Adam − Adam optimizer.\n",
    "keras.optimizers.Adam(\n",
    "   learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vso5bRqaC30B"
   },
   "outputs": [],
   "source": [
    "# Adamax − Adamax optimizer from Adam.\n",
    "keras.optimizers.Adamax(learning_rate = 0.002, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PIU1WX5DJ1Y"
   },
   "source": [
    "## Metrics\n",
    "\n",
    "In machine learning, Metrics is used to evaluate the performance of your model. It is similar to loss function, but not used in training process. Keras provides quite a few metrics as a module, metrics and they are as follows\n",
    "\n",
    "    accuracy\n",
    "    binary_accuracy\n",
    "    categorical_accuracy\n",
    "    sparse_categorical_accuracy\n",
    "    top_k_categorical_accuracy\n",
    "    sparse_top_k_categorical_accuracy\n",
    "    cosine_proximity\n",
    "    clone_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1650207821317,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "PrlJUd1lDNB2"
   },
   "outputs": [],
   "source": [
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HabvDPq_DSrd"
   },
   "source": [
    "## Compile the model\n",
    "\n",
    "Keras model provides a method, compile() to compile the model. The argument and default value of the compile() method is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1650207861224,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "KU2ctg7jDSV6"
   },
   "outputs": [],
   "source": [
    "from keras import losses \n",
    "from keras import optimizers \n",
    "from keras import metrics \n",
    "\n",
    "model.compile(loss = 'mean_squared_error',  \n",
    "   optimizer = 'sgd', metrics = [metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X0grOe-Diax"
   },
   "source": [
    "where,\n",
    "\n",
    "    loss function is set as mean_squared_error\n",
    "    optimizer is set as sgd\n",
    "    metrics is set as metrics.categorical_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4N7jVZZCgII"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Models are trained by NumPy arrays using fit(). The main purpose of this fit function is used to evaluate your model on training. This can be also used for graphing model performance. It has the following syntax −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdVTABTfDrca"
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs = , batch_size = )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf-DnZN4DxdM"
   },
   "source": [
    "Here,\n",
    "\n",
    "    X, y − It is a tuple to evaluate your data.\n",
    "    epochs − no of times the model is needed to be evaluated during training.\n",
    "    batch_size − training instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95vjfkiSD0vu"
   },
   "source": [
    "# EXAMPLE OF KERAS SIMPLE MODEL TRAINING USING THE NUMPY\n",
    "\n",
    "## Create data\n",
    "\n",
    "Let us create a random data using numpy for x and y with the help of below mentioned command −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1650208078330,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "gHEcNakWD0hh"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "x_train = np.random.random((100,4,8)) \n",
    "y_train = np.random.random((100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650208104849,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "IWT0WI1FEQEj"
   },
   "outputs": [],
   "source": [
    "# Now, create random validation data,\n",
    "\n",
    "x_val = np.random.random((100,4,8)) \n",
    "y_val = np.random.random((100,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1650208126913,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "1fUtanBqEWmL"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "# Let us create simple sequential model −\n",
    "\n",
    "from keras.models import Sequential \n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650208148400,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "xtSjZsKvEdnl"
   },
   "outputs": [],
   "source": [
    "# Add layers\n",
    "\n",
    "# Create layers to add model −\n",
    "\n",
    "from keras.layers import LSTM, Dense \n",
    "\n",
    "# add a sequence of vectors of dimension 16 \n",
    "model.add(LSTM(16, return_sequences = True)) \n",
    "model.add(Dense(10, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650208166261,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "pyYiIGRdEiyK"
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "# Now model is defined. You can compile using the below command −\n",
    "\n",
    "model.compile(\n",
    "   loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "error",
     "timestamp": 1650209218707,
     "user": {
      "displayName": "Bala Guga Gopal S",
      "userId": "13929374687942600810"
     },
     "user_tz": -330
    },
    "id": "q6k_X3IaEnUv",
    "outputId": "d729e593-faee-4539-98c6-77f7b74b7924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3bccb69f234f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Now we apply fit() function to train our data −\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#Apply fit()\n",
    "\n",
    "# Now we apply fit() function to train our data −\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 32, epochs = 5, validation_data = (x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vgG5M97EPy8"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOoVg0kiX3+a7CIBbRuq36M",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
